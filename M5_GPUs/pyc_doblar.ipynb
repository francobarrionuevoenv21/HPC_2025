{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yiAfHzW6ZLt5"},"outputs":[],"source":["# 1D / 1 Block\n","#  doblar vector\n","#   Implementación con SourceModule de duplicar elementos de un vector.\n","\n","!pip install pycuda\n","\n","import pycuda.driver as drv\n","import pycuda.autoinit\n","from   pycuda.compiler import SourceModule\n","import numpy as np\n","import time\n","\n","\n","if __name__ == '__main__':\n","\n","    # Parametros de configuracion:\n","    drv.init()\n","    dev = drv.Device(0) # Device 0\n","    max_thr_per_blk = dev.MAX_THREADS_PER_BLOCK\n","    print(\"MAX_THREADS_PER_BLOCK: \", max_thr_per_blk)\n","\n","    # 1. Definir kenel\n","    mod = SourceModule (\"\"\"\n","    __global__ void doblar_vector(float *a) {\n","        int i = threadIdx.x;\n","        if (i < 8) {\n","            a[i] = a[i] * 2;\n","        }\n","    }\n","    \"\"\")\n","\n","    # 2. Reserva memoria en GPU:\n","    SIZE = 8\n","    a = np.arange(SIZE, dtype=np.float32)\n","    print(\"Vector:\", a)\n","    a_gpu = drv.mem_alloc(a.nbytes)\n","\n","    # 3. Transferir datos host->GPU\n","    drv.memcpy_htod(a_gpu, a)\n","\n","    # 4. Invoca kernel\n","    doblar = mod.get_function(\"doblar_vector\")\n","    doblar(a_gpu, block = (SIZE, 1, 1), \n","                  grid  = (   1, 1, 1) )\n","\n","    # 5. Transferir datos GPU->host\n","    a_doubled = np.empty_like(a)\n","    drv.memcpy_dtoh(a_doubled, a_gpu)\n","\n","    print(\"Vector doble:\", a_doubled)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9uo_JZ6PIuAK"},"outputs":[],"source":["# 1D / N Blocks\n","#  dooblar vector\n","#   Implementación con SourceModule de duplicar elementos de un vector.\n","\n","!pip install pycuda\n","\n","import pycuda.driver as drv\n","import pycuda.autoinit\n","from   pycuda.compiler import SourceModule\n","import numpy as np\n","import time\n","\n","\n","if __name__ == '__main__':\n","\n","    # Parametros de configuracion:\n","    drv.init()\n","    dev = drv.Device(0) # Device 0\n","    max_thr_per_blk = dev.MAX_THREADS_PER_BLOCK\n","    print(\"MAX_THREADS_PER_BLOCK: \", max_thr_per_blk)\n","\n","    # 1. Definir kenel\n","    mod = SourceModule (\"\"\"\n","    __global__ void doblar_vector(float *a) {\n","        int i = (blockDim.x * blockIdx.x) + threadIdx.x;\n","        if (i < 2048) {\n","            a[i] = a[i] * 2;\n","        }\n","    }\n","    \"\"\")\n","\n","    # 2. Reserva memoria en GPU:\n","    SIZE = 2048\n","    a = np.arange(SIZE, dtype=np.float32)\n","    print(\"Vector:\", a)\n","    a_gpu = drv.mem_alloc(a.nbytes)\n","\n","    # 3. Transferir datos host->GPU\n","    drv.memcpy_htod(a_gpu, a)\n","\n","    # 4. Invoca kernel\n","    doblar = mod.get_function(\"doblar_vector\")\n","    doblar(a_gpu, block = (max_thr_per_blk, 1, 1), \n","                  grid  = (2, 1, 1))\n","\n","    # 5. Transferir datos GPU->host\n","    a_doubled = np.empty_like(a)\n","    drv.memcpy_dtoh(a_doubled, a_gpu)\n","\n","    print(\"Vector doble:\", a_doubled)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lw8t2ElXM4gp"},"outputs":[],"source":["#  2D / 1 Block\n","#   doblar matriz\n","#   Implementación con SourceModule de duplicar elementos de una matriz.\n","\n","\n","!pip install pycuda\n","\n","import pycuda.driver as drv\n","import pycuda.autoinit\n","from   pycuda.compiler import SourceModule\n","import numpy as np\n","import time\n","\n","\n","if __name__ == '__main__':\n","\n","    # Parametros de configuracion:\n","    drv.init()\n","    dev = drv.Device(0) # Device 0\n","    max_thr_per_blk = dev.MAX_THREADS_PER_BLOCK\n","    print(\"MAX_THREADS_PER_BLOCK: \", max_thr_per_blk)\n","\n","    # 1. Definir kenel\n","    mod = SourceModule (\"\"\"\n","    __global__ void doblar_matriz(float *a) {\n","        int row = (blockDim.x * blockIdx.x) + threadIdx.x;\n","        int col = (blockDim.y * blockIdx.y) + threadIdx.y;\n","\n","        if ((row < 5) && (col < 5)) {\n","            int i = (row * 5) + col;   /* Row major */ \n","            a[i] = a[i] * 2;  \n","        }\n","    }\n","    \"\"\")\n","\n","    # 2. Reserva memoria en GPU:\n","    H = 5\n","    W = 5\n","    a = np.arange(H * W, dtype=np.float32).reshape(H, W)\n","    print(\"Matriz:\", a, a.nbytes)\n","    a_gpu = drv.mem_alloc(a.nbytes)\n","\n","    # 3. Transferir datos host->GPU\n","    drv.memcpy_htod(a_gpu, a)\n","\n","    # 4. Invoca kernel\n","    doblar = mod.get_function(\"doblar_matriz\")\n","    doblar(a_gpu, block = (H, W, 1), \n","                  grid  = (1, 1, 1))\n","\n","    # 5. Transferir datos GPU->host\n","    a_doubled = np.arange(H * W, dtype=np.float32) \n","    drv.memcpy_dtoh(a_doubled, a_gpu)\n","\n","    print(\"Matriz doble:\", a_doubled.reshape(H, W))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p7LTxI4NEFdz"},"outputs":[],"source":["# 2D / N bloques\n","#  doblar matriz\n","#   Implementación con SourceModule de duplicar elementos de una matriz.\n","\n","!pip install pycuda\n","\n","import pycuda.driver as drv\n","import pycuda.autoinit\n","from   pycuda.compiler import SourceModule\n","import numpy as np\n","import time\n","\n","\n","if __name__ == '__main__':\n","\n","    # 1. Definir kenel\n","    mod = SourceModule (\"\"\"\n","    __global__ void doblar_matriz(float *a) {\n","        int row = (blockDim.x * blockIdx.x) + threadIdx.x;\n","        int col = (blockDim.y * blockIdx.y) + threadIdx.y;\n","\n","        if ((row < 64) && (col < 64)) {\n","            int i = (row * 64) + col; /* Row major */ \n","            a[i] = a[i] * 2;  \n","        }\n","    }\n","    \"\"\")\n","\n","    # 2. Reserva memoria en GPU:\n","    H = 64\n","    W = 64\n","    a = np.arange(H * W, dtype=np.float32).reshape(H, W)\n","    print(\"Matriz:\", a)\n","    a_gpu = drv.mem_alloc(a.nbytes)\n","\n","    # 3. Transferir datos host->GPU\n","    drv.memcpy_htod(a_gpu, a)\n","\n","    # 4. Invoca kernel\n","    dim = 32       # Threads per block: 32 x 32. En total 1024 máximo.\n","    grid_x = 2     \n","    grid_y = 2\n","    doblar = mod.get_function(\"doblar_matriz\")\n","    doblar(a_gpu, block = (dim, dim, 1),\n","                  grid  = (grid_x, grid_y, 1) )\n","\n","    # 5. Transferir datos GPU->host\n","    a_doubled = np.arange(H * W, dtype=np.float32) \n","    drv.memcpy_dtoh(a_doubled, a_gpu)\n","\n","    print(\"Matriz doble:\", a_doubled.reshape(H, W))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pkwg-B29AIRB"},"outputs":[],"source":["# 2D / N bloques (no multiplo)\n","#  doblar matriz\n","#   Implementación con SourceModule de duplicar elementos de una matriz.\n","\n","\n","!pip install pycuda\n","\n","import pycuda.driver as drv\n","import pycuda.autoinit\n","from   pycuda.compiler import SourceModule\n","import numpy as np\n","import time\n","import math\n","\n","\n","if __name__ == '__main__':\n","\n","    # 1. Definir kenel\n","    mod = SourceModule (\"\"\"\n","    __global__ void doblar_matriz(float *a, int rows, int cols) {\n","        int row = (blockDim.x * blockIdx.x) + threadIdx.x;\n","        int col = (blockDim.y * blockIdx.y) + threadIdx.y;\n","\n","        if ((row < rows) && (col < cols)) {\n","            int i = (row * cols) + col;    /* Row major */ \n","            a[i] = a[i] * 2;  \n","        }\n","    }\n","    \"\"\")\n","\n","    # 2. Reserva memoria en GPU:\n","    H = 80    # Filas\n","    W = 74    # Columnas\n","    a = np.arange(H * W, dtype=np.float32).reshape(H, W)\n","    print(\"Matriz:\", a)\n","    a_gpu = drv.mem_alloc(a.nbytes)\n","\n","    # 3. Transferir datos host->GPU\n","    drv.memcpy_htod(a_gpu, a)\n","\n","    # 4. Invoca kernel\n","    dim = 32                      # Block = 32 x 32 threeads\n","    grid_x = math.ceil(H / dim)   # Cuantos bloques X necesito\n","    grid_y = math.ceil(W / dim)   # Cuantos bloques Y necesito\n","    print(\"Numero de threads por block:\", dim, dim)\n","    print(\"Numero de blocks por grid:\", grid_x, grid_y)\n","\n","    doblar = mod.get_function(\"doblar_matriz\")\n","    doblar(a_gpu, np.intc(H), np.intc(W), \n","           block = (dim, dim, 1),\n","           grid  = (grid_x, grid_y, 1) )\n","\n","    # 5. Transferir datos GPU->host\n","    a_doubled = np.arange(H * W, dtype=np.float32) # np.empty_like(a)\n","    drv.memcpy_dtoh(a_doubled, a_gpu)\n","\n","    print(\"Matriz doble:\", a_doubled.reshape(H, W))\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"pyc_doblar.ipynb","provenance":[],"authorship_tag":"ABX9TyPra0XLVlXVcsek8lRL/M93"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}