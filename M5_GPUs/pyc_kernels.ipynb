{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ai8_bBkHP4CH"},"source":["### Kernel Patterns\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P64iXvsSr87k"},"outputs":[],"source":["# ElementWiseKernel\n","\n","!pip install pycuda\n","\n","import pycuda.autoinit\n","from   pycuda import gpuarray\n","from   pycuda.elementwise import ElementwiseKernel\n","import numpy as np\n","import time\n","\n","\n","prod_kernel = ElementwiseKernel (\n","    arguments = \"float *a, float *b, float *c\",\n","    operation = \"c[i] = a[i] * b[i];\",\n","    name      = \"prod_kernel\"\n",")\n","\n","\n","if __name__ == '__main__':\n","\n","    size = 1024\n","\n","    h_a = np.random.rand(size * size).reshape(size, size).astype(np.float32)\n","    h_b = np.random.rand(size * size).reshape(size, size).astype(np.float32)\n","\n","    print(\"Matrix A: \", h_a)\n","    print(\"Matrix B: \", h_b)\n","\n","    start = time.time()\n","    d_a = gpuarray.to_gpu(h_a)\n","    d_b = gpuarray.to_gpu(h_b)\n","    d_c = gpuarray.empty_like(d_a)\n","    \n","    prod_kernel(d_a, d_b, d_c)\n","\n","    h_c = d_c.get()\n","    end = time.time()\n","    gpu_time = end - start\n","    print(\"GPU time: %.6f\" % (gpu_time))\n","    print(\"Matrix: \", h_c)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hDOnLqQv-7wa"},"outputs":[],"source":["# Mandelbrot\n","\n","!pip install pycuda\n","\n","\n","import pycuda.driver as CUDA\n","import pycuda.autoinit\n","from   pycuda import gpuarray\n","import numpy as np\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","mpl.use('Agg')\n","import pandas as pd\n","import time\n","\n","from pycuda.elementwise import ElementwiseKernel\n","\n","#  Poniendo w y h a 512 los tiempos son aprox:\n","#    CPU ~ 36 secs\n","#    GPU ~ 0.2 secs\n","\n","def cpu_mandelbrot(w, h, r_low, r_high, i_low, i_high, max_iters, upper_bound):\n","\n","    real_vals = np.linspace(r_low, r_high, w)\n","    imag_vals = np.linspace(i_low, i_high, h)\n","\n","    # we will represent members as 1, non-members as 0.\n","\n","    mandelbrot_graph = np.ones((h,w), dtype=np.float32)\n","\n","    for x in range(w):\n","\n","        for y in range(h):\n","\n","            c = np.complex64( real_vals[x] + imag_vals[y] * 1j  )\n","            z = np.complex64(0)\n","\n","            for i in range(max_iters):\n","\n","                z = z**2 + c\n","\n","                if(np.abs(z) > upper_bound):\n","                    mandelbrot_graph[y,x] = 0\n","                    break\n","\n","    return mandelbrot_graph\n","\n","\n","\n","mandel_ker = ElementwiseKernel(\n","\"pycuda::complex<float> *lattice, float *mandelbrot_graph, int max_iters, float upper_bound\",\n","\n","\"\"\"\n","mandelbrot_graph[i] = 1;\n","pycuda::complex<float> c = lattice[i];\n","pycuda::complex<float> z(0,0);\n","\n","for (int j = 0; j < max_iters; j++) {\n","    z = (z * z) + c;\n","    if(abs(z) > upper_bound) {\n","        mandelbrot_graph[i] = 0;\n","        break;\n","    }\n","}\n","\"\"\",\n","\n","\"mandel_ker\")\n","\n","\n","\n","def mandelbrot (w, h, r_low, r_high, i_low, i_high, max_iters, upper_bound):\n","    real_values = np.matrix( np.linspace(r_low,  r_high, w, dtype=np.complex64))\n","    img_values  = np.matrix( np.linspace(i_high, i_low,  h, dtype=np.complex64)) * 1j\n","\n","    m_lattice = np.array(real_values + img_values.transpose(), dtype=np.complex64)\n","    # print(\"Lattice:\", m_lattice.shape)\n","    # print(m_lattice)\n","    # copy complex lattice to the GPU\n","    m_lattice_gpu = gpuarray.to_gpu(m_lattice)\n","    # allocate an empty array on the GPU\n","    m_graph_gpu = gpuarray.empty(shape=m_lattice.shape, dtype=np.float32)\n","    # Launch kernel\n","    mandel_ker(m_lattice_gpu, m_graph_gpu, np.int32(max_iters), np.float32(upper_bound))\n","    # GPU to host memoory\n","    m_graph = m_graph_gpu.get()\n","    return m_graph\n","\n","\n","if __name__ == '__main__':\n","\n","    start = time.time()\n","    m = cpu_mandelbrot(w =256, h = 256,\n","                   r_low = -2, r_high = 2,\n","                   i_low = -2, i_high = 2,\n","                   max_iters = 500,\n","                   upper_bound = 2.5)\n","    end = time.time()\n","    cpu_time = end - start\n","    print(\"CPU time:\", cpu_time)\n","\n","    start = time.time()\n","    m_gpu = mandelbrot(w =256, h = 256,\n","                   r_low = -2, r_high = 2,\n","                   i_low = -2, i_high = 2,\n","                   max_iters = 500,\n","                   upper_bound = 2.5)\n","    end = time.time()\n","    gpu_time = end - start\n","    print(\"GPU time:\", gpu_time)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZpMebo6i0rQT"},"outputs":[],"source":["# Parallel Scan kernel:\n","\n","!pip install pycuda\n","\n","import pycuda.autoinit\n","from   pycuda import gpuarray\n","import numpy as np\n","from pycuda.scan import InclusiveScanKernel, ExclusiveScanKernel\n","\n","if __name__ == '__main__':\n","    \n","    cumsum_i = InclusiveScanKernel(\n","        dtype       = np.float32, \n","        neutral     = \"0\",\n","        scan_expr   = \"a+b\", \n","        name_prefix = \"cumsum\"\n","    )\n","    \n","    cumsum_e = ExclusiveScanKernel(\n","        dtype       = np.float32, \n","        neutral     = \"0\",\n","        scan_expr   = \"a+b\", \n","        name_prefix = \"cumsum\"\n","    )\n","\n","    h_i = np.arange(10, dtype=np.float32)\n","    d_i = gpuarray.to_gpu(h_i)    \n","    cumsum_i(d_i)\n","    h_i = d_i.get()\n","    print(\"Resultado (inclusive): \", h_i)\n","\n","    h_e = np.arange(10, dtype=np.float32)\n","    d_e = gpuarray.to_gpu(h_e)    \n","    cumsum_e(d_e)\n","    h_e = d_e.get()\n","    print(\"Resultado (exclusive) \", h_e)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7vRyk2YYUb1n"},"outputs":[],"source":["# Otros patrones de kernel: \n","!pip install pycuda\n","\n","import pycuda.autoinit\n","from   pycuda import gpuarray\n","import numpy as np\n","from pycuda.reduction import ReductionKernel\n","\n","if __name__ == '__main__':\n","    \n","    dot = ReductionKernel(        \n","        arguments   = \"const float *x, const float *y\",\n","        map_expr    = \"x[i] * y[i]\", \n","        reduce_expr = \"a+b\", \n","        neutral     = \"0\",\n","        dtype_out   = np.float32\n","    )\n","    \n","    h_a = np.arange(10, dtype=np.float32)\n","    h_b = np.arange(10, dtype=np.float32)\n","\n","    d_a = gpuarray.to_gpu(h_a)\n","    d_b = gpuarray.to_gpu(h_b)\n","\n","    d_c = dot(d_a, d_b)\n","\n","    h_c = d_c.get()\n","    print(\"Resultado: \", h_c)\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNUeg3U8WHUz8W2g7L1Send","collapsed_sections":[],"name":"pyc_kernels.ipynb","provenance":[{"file_id":"19UahPn0hfGi-TkXnL9Dq740X7-c_ZkLX","timestamp":1658496959891}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat":4,"nbformat_minor":0}
